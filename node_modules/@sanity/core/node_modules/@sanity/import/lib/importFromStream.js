"use strict";

function _objectSpread(target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i] != null ? arguments[i] : {}; var ownKeys = Object.keys(source); if (typeof Object.getOwnPropertySymbols === 'function') { ownKeys = ownKeys.concat(Object.getOwnPropertySymbols(source).filter(function (sym) { return Object.getOwnPropertyDescriptor(source, sym).enumerable; })); } ownKeys.forEach(function (key) { _defineProperty(target, key, source[key]); }); } return target; }

function _defineProperty(obj, key, value) { if (key in obj) { Object.defineProperty(obj, key, { value: value, enumerable: true, configurable: true, writable: true }); } else { obj[key] = value; } return obj; }

function asyncGeneratorStep(gen, resolve, reject, _next, _throw, key, arg) { try { var info = gen[key](arg); var value = info.value; } catch (error) { reject(error); return; } if (info.done) { resolve(value); } else { Promise.resolve(value).then(_next, _throw); } }

function _asyncToGenerator(fn) { return function () { var self = this, args = arguments; return new Promise(function (resolve, reject) { var gen = fn.apply(self, args); function _next(value) { asyncGeneratorStep(gen, resolve, reject, _next, _throw, "next", value); } function _throw(err) { asyncGeneratorStep(gen, resolve, reject, _next, _throw, "throw", err); } _next(undefined); }); }; }

const os = require('os');

const fs = require('fs');

const path = require('path');

const miss = require('mississippi');

const gunzipMaybe = require('gunzip-maybe');

const peek = require('peek-stream');

const isTar = require('is-tar');

const tar = require('tar-fs');

const globby = require('globby');

const debug = require('debug')('sanity:import:stream');

const _require = require('lodash'),
      noop = _require.noop;

const getJsonStreamer = require('./util/getJsonStreamer');

module.exports = (stream, options, importers) => new Promise((resolve, reject) => {
  const outputPath = path.join(os.tmpdir(), 'sanity-import');
  debug('Importing from stream');
  let isTarStream = false;
  let jsonDocuments;
  const uncompressStream = miss.pipeline(gunzipMaybe(), untarMaybe());
  miss.pipe(stream, uncompressStream, err => {
    if (err) {
      reject(err);
      return;
    }

    if (isTarStream) {
      findAndImport();
    } else {
      resolve(importers.fromArray(jsonDocuments, options));
    }
  });

  function untarMaybe() {
    return peek({
      newline: false,
      maxBuffer: 300
    }, (data, swap) => {
      if (isTar(data)) {
        debug('Stream is a tarball, extracting to %s', outputPath);
        isTarStream = true;
        return swap(null, tar.extract(outputPath));
      }

      debug('Stream is an ndjson file, streaming JSON');
      const jsonStreamer = getJsonStreamer();
      const concatter = miss.concat(resolveNdjsonStream);
      const ndjsonStream = miss.pipeline(jsonStreamer, concatter);
      ndjsonStream.on('error', err => {
        uncompressStream.emit('error', err);
        destroy([uncompressStream, jsonStreamer, concatter, ndjsonStream]);
        reject(err);
      });
      return swap(null, ndjsonStream);
    });
  }

  function resolveNdjsonStream(documents) {
    debug('Finished reading ndjson stream');
    jsonDocuments = documents;
  }

  function findAndImport() {
    return _findAndImport.apply(this, arguments);
  }

  function _findAndImport() {
    _findAndImport = _asyncToGenerator(function* () {
      debug('Tarball extracted, looking for ndjson');
      const files = yield globby('**/*.ndjson', {
        cwd: outputPath,
        deep: 2,
        absolute: true
      });

      if (!files.length) {
        reject(new Error('ndjson-file not found in tarball'));
        return;
      }

      const importBaseDir = path.dirname(files[0]);
      resolve(importers.fromFolder(importBaseDir, _objectSpread({}, options, {
        deleteOnComplete: true
      }), importers));
    });
    return _findAndImport.apply(this, arguments);
  }
});

function destroy(streams) {
  streams.forEach(stream => {
    if (isFS(stream)) {
      // use close for fs streams to avoid fd leaks
      stream.close(noop);
    } else if (isRequest(stream)) {
      // request.destroy just do .end - .abort is what we want
      stream.abort();
    } else if (isFn(stream.destroy)) {
      stream.destroy();
    }
  });
}

function isFn(fn) {
  return typeof fn === 'function';
}

function isFS(stream) {
  return (stream instanceof (fs.ReadStream || noop) || stream instanceof (fs.WriteStream || noop)) && isFn(stream.close);
}

function isRequest(stream) {
  return stream.setHeader && isFn(stream.abort);
}