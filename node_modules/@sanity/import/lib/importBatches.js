"use strict";

function asyncGeneratorStep(gen, resolve, reject, _next, _throw, key, arg) { try { var info = gen[key](arg); var value = info.value; } catch (error) { reject(error); return; } if (info.done) { resolve(value); } else { Promise.resolve(value).then(_next, _throw); } }

function _asyncToGenerator(fn) { return function () { var self = this, args = arguments; return new Promise(function (resolve, reject) { var gen = fn.apply(self, args); function _next(value) { asyncGeneratorStep(gen, resolve, reject, _next, _throw, "next", value); } function _throw(err) { asyncGeneratorStep(gen, resolve, reject, _next, _throw, "throw", err); } _next(undefined); }); }; }

const pMap = require('p-map');

const progressStepper = require('./util/progressStepper');

const retryOnFailure = require('./util/retryOnFailure');

const DOCUMENT_IMPORT_CONCURRENCY = 3;

function importBatches(_x, _x2) {
  return _importBatches.apply(this, arguments);
}

function _importBatches() {
  _importBatches = _asyncToGenerator(function* (batches, options) {
    const progress = progressStepper(options.onProgress, {
      step: 'Importing documents',
      total: batches.length
    });
    const mapOptions = {
      concurrency: DOCUMENT_IMPORT_CONCURRENCY
    };
    const batchSizes = yield pMap(batches, importBatch.bind(null, options, progress), mapOptions);
    return batchSizes.reduce((prev, add) => prev + add, 0);
  });
  return _importBatches.apply(this, arguments);
}

function importBatch(options, progress, batch) {
  const client = options.client,
        operation = options.operation;
  const maxRetries = operation === 'create' ? 1 : 3;
  return retryOnFailure(() => batch.reduce((trx, doc) => trx[operation](doc), client.transaction()).commit({
    visibility: 'async'
  }).then(progress).then(res => res.results.length), {
    maxRetries
  });
}

module.exports = importBatches;